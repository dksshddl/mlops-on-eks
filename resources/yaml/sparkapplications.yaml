apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: spark-pi-python-7
  namespace: default
spec:
  type: Python
  pythonVersion: "3"
  mode: cluster #cluster
  image: 013596862746.dkr.ecr.ap-northeast-2.amazonaws.com/ml-on-eks/spark:v4
  imagePullPolicy: IfNotPresent
  mainApplicationFile: s3a://spark/python/main.py
  sparkVersion: 3.5.5
  sparkConf:
    spark.jars.packages: "org.apache.hadoop:hadoop-aws:3.3.4,software.amazon.awssdk:s3:2.31.30,software.amazon.awssdk:sts:2.31.30,software.amazon.awssdk:auth:2.31.30,org.apache.hadoop:hadoop-common:3.3.4,org.postgresql:postgresql:42.3.3"
    spark.kubernetes.file.upload.path: "s3a://spark"
    spark.jars.ivy: "/tmp/.ivy2"
  hadoopConf:
    fs.s3a.endpoint: "http://minio:80"
    fs.s3a.access.key: "minio"
    fs.s3a.secret.key: "minio123"
    fs.s3a.impl: "org.apache.hadoop.fs.s3a.S3AFileSystem"
    fs.s3a.path.style.access: "true"
    fs.s3a.connection.ssl.enabled: "false"
    fs.s3a.aws.credentials.provider: "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider"
  driver:
    cores: 1
    memory: 2g
    serviceAccount: spark-operator-spark
  executor:
    instances: 1
    cores: 1
    memory: 2g
    labels:
      type: spark-worker
    tolerations:
    - key: type
      operator: "Equal"
      value: spark-worker
      effect: "NoSchedule"
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: type
              operator: In
              values:
              - spark-worker   